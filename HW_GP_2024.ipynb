{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQEHAFhU0xzx"
   },
   "source": [
    "# Regression with Gaussian Processes\n",
    "\n",
    "------------------------------------------------------\n",
    "*Machine Learning, Master in Big Data Analytics, 2023-2024*\n",
    "\n",
    "*Pablo M. Olmos olmos@tsc.uc3m.es, Emilio Parrado Hernandez, eparrado@ing.uc3m.es*\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "The aim of this homework is to solve a real data problem using Gaussian Processes.\n",
    "\n",
    "The problem is the prediction of both the heating load (HL) and cooling load (CL) of residential buildings. We consider eight input variables for each building: relative compactness, surface area, wall area, roof area, overall height, orientation, glazing area, glazing area distribution.\n",
    "\n",
    "In this [paper](https://www.sciencedirect.com/science/article/pii/S037877881200151X) you can find a detailed description of the problem and a solution based on linear regression [(iteratively reweighted least squares (IRLS) algorithm)](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=10&ved=2ahUKEwjZuoLY2OjgAhUs3uAKHUZ7BVcQFjAJegQIAhAC&url=https%3A%2F%2Fpdfs.semanticscholar.org%2F9b92%2F18e7233f4d0b491e1582c893c9a099470a73.pdf&usg=AOvVaw3YDwqZh1xyF626VqfnCM2k) and random forests. Using GPs, our goal is not only estimate accurately both HL and CL, but also get a measure of uncertainty in our predictions.\n",
    "\n",
    "The data set can be downloaded from the [UCI repository](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9XScdSK0xz3"
   },
   "source": [
    "## 1. Loading and preparing the data\n",
    "\n",
    "* Download the dataset\n",
    "* Divide at random the dataset into train (80%) and test (20%) datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lvFIbLzT0xz3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relative Compactness</th>\n",
       "      <th>Surface Area</th>\n",
       "      <th>Wall Area</th>\n",
       "      <th>Roof Area</th>\n",
       "      <th>Overall Height</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Glazing Area</th>\n",
       "      <th>Glazing Area Distribution</th>\n",
       "      <th>Heating Load</th>\n",
       "      <th>Cooling Load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.82</td>\n",
       "      <td>612.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>23.53</td>\n",
       "      <td>27.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.64</td>\n",
       "      <td>784.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>18.90</td>\n",
       "      <td>22.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>29.27</td>\n",
       "      <td>29.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>32.84</td>\n",
       "      <td>32.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.66</td>\n",
       "      <td>759.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>11.43</td>\n",
       "      <td>14.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.76</td>\n",
       "      <td>661.5</td>\n",
       "      <td>416.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>32.21</td>\n",
       "      <td>33.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.86</td>\n",
       "      <td>588.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>26.33</td>\n",
       "      <td>27.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.71</td>\n",
       "      <td>710.5</td>\n",
       "      <td>269.5</td>\n",
       "      <td>220.50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>10.67</td>\n",
       "      <td>14.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>28.62</td>\n",
       "      <td>30.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>28.83</td>\n",
       "      <td>29.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Relative Compactness  Surface Area  Wall Area  Roof Area  Overall Height  \\\n",
       "60                   0.82         612.5      318.5     147.00             7.0   \n",
       "618                  0.64         784.0      343.0     220.50             3.5   \n",
       "346                  0.86         588.0      294.0     147.00             7.0   \n",
       "294                  0.90         563.5      318.5     122.50             7.0   \n",
       "231                  0.66         759.5      318.5     220.50             3.5   \n",
       "..                    ...           ...        ...        ...             ...   \n",
       "71                   0.76         661.5      416.5     122.50             7.0   \n",
       "106                  0.86         588.0      294.0     147.00             7.0   \n",
       "270                  0.71         710.5      269.5     220.50             3.5   \n",
       "435                  0.98         514.5      294.0     110.25             7.0   \n",
       "102                  0.90         563.5      318.5     122.50             7.0   \n",
       "\n",
       "     Orientation  Glazing Area  Glazing Area Distribution  Heating Load  \\\n",
       "60             2          0.10                          1         23.53   \n",
       "618            4          0.40                          2         18.90   \n",
       "346            4          0.25                          2         29.27   \n",
       "294            4          0.25                          1         32.84   \n",
       "231            5          0.10                          4         11.43   \n",
       "..           ...           ...                        ...           ...   \n",
       "71             5          0.10                          1         32.21   \n",
       "106            4          0.10                          2         26.33   \n",
       "270            4          0.10                          5         10.67   \n",
       "435            5          0.25                          4         28.62   \n",
       "102            4          0.10                          2         28.83   \n",
       "\n",
       "     Cooling Load  \n",
       "60          27.31  \n",
       "618         22.09  \n",
       "346         29.90  \n",
       "294         32.71  \n",
       "231         14.83  \n",
       "..            ...  \n",
       "71          33.67  \n",
       "106         27.36  \n",
       "270         14.26  \n",
       "435         30.12  \n",
       "102         29.36  \n",
       "\n",
       "[614 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "data = pd.read_excel('ENB2012_data.xlsx')\n",
    "\n",
    "# Define the new column names\n",
    "new_column_names = {\n",
    "    'X1': 'Relative Compactness',\n",
    "    'X2': 'Surface Area',\n",
    "    'X3': 'Wall Area',\n",
    "    'X4': 'Roof Area',\n",
    "    'X5': 'Overall Height',\n",
    "    'X6': 'Orientation',\n",
    "    'X7': 'Glazing Area',\n",
    "    'X8': 'Glazing Area Distribution',\n",
    "    'Y1': 'Heating Load',\n",
    "    'Y2': 'Cooling Load'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "data = data.rename(columns=new_column_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline results: Random Forests (10%)\n",
    "\n",
    "Train a Random Forests selecting the number of trees in the forest and the maximum number of leaves using cross validation. \n",
    "\n",
    "**Print the scores in the test set for each target. These will be our baseline results.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Heating Load: 0.49969530508308696\n",
      "RMSE for Cooling Load: 1.7547635597380087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Separate features and target variables\n",
    "X = data.drop(columns=['Heating Load', 'Cooling Load'])\n",
    "y_heating = data['Heating Load']\n",
    "y_cooling = data['Cooling Load']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train_heating, y_test_heating = train_test_split(X, y_heating, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_cooling, y_test_cooling = train_test_split(X, y_cooling, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps for numerical features\n",
    "numeric_features = X.columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Define the Random Forest Regressor pipeline\n",
    "rf_pipeline_heating = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "rf_pipeline_cooling = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 150],\n",
    "    'regressor__max_leaf_nodes': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# Perform cross-validation to find the best hyperparameters for heating load\n",
    "grid_search_heating = RandomizedSearchCV(rf_pipeline_heating, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_heating.fit(X_train, y_train_heating)\n",
    "\n",
    "# Perform cross-validation to find the best hyperparameters for cooling load\n",
    "grid_search_cooling = RandomizedSearchCV(rf_pipeline_cooling, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_cooling.fit(X_train, y_train_cooling)\n",
    "\n",
    "# Get the best estimators\n",
    "best_rf_heating = grid_search_heating.best_estimator_\n",
    "best_rf_cooling = grid_search_cooling.best_estimator_\n",
    "\n",
    "# Fit the models on the training data\n",
    "best_rf_heating.fit(X_train, y_train_heating)\n",
    "best_rf_cooling.fit(X_train, y_train_cooling)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_heating = best_rf_heating.predict(X_test)\n",
    "y_pred_cooling = best_rf_cooling.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for each target variable\n",
    "rmse_heating = mean_squared_error(y_test_heating, y_pred_heating, squared=False)\n",
    "rmse_cooling = mean_squared_error(y_test_cooling, y_pred_cooling, squared=False)\n",
    "\n",
    "print(\"RMSE for Heating Load:\", rmse_heating)\n",
    "print(\"RMSE for Cooling Load:\", rmse_cooling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use attribute `feature_importances_` to discuss which are, for RF, the most informative features to predict each target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance for Heating Load:\n",
      "                     Feature  Importance for Heating Load  \\\n",
      "0       Relative Compactness                     0.375779   \n",
      "1               Surface Area                     0.196229   \n",
      "4             Overall Height                     0.173437   \n",
      "3                  Roof Area                     0.128402   \n",
      "6               Glazing Area                     0.080092   \n",
      "2                  Wall Area                     0.034538   \n",
      "7  Glazing Area Distribution                     0.010775   \n",
      "5                Orientation                     0.000748   \n",
      "\n",
      "   Importance for Cooling Load  \n",
      "0                     0.464365  \n",
      "1                     0.078125  \n",
      "4                     0.280514  \n",
      "3                     0.060578  \n",
      "6                     0.048570  \n",
      "2                     0.039623  \n",
      "7                     0.016380  \n",
      "5                     0.011844  \n",
      "\n",
      "Feature importance for Cooling Load:\n",
      "                     Feature  Importance for Heating Load  \\\n",
      "0       Relative Compactness                     0.375779   \n",
      "4             Overall Height                     0.173437   \n",
      "1               Surface Area                     0.196229   \n",
      "3                  Roof Area                     0.128402   \n",
      "6               Glazing Area                     0.080092   \n",
      "2                  Wall Area                     0.034538   \n",
      "7  Glazing Area Distribution                     0.010775   \n",
      "5                Orientation                     0.000748   \n",
      "\n",
      "   Importance for Cooling Load  \n",
      "0                     0.464365  \n",
      "4                     0.280514  \n",
      "1                     0.078125  \n",
      "3                     0.060578  \n",
      "6                     0.048570  \n",
      "2                     0.039623  \n",
      "7                     0.016380  \n",
      "5                     0.011844  \n"
     ]
    }
   ],
   "source": [
    "# Get feature importances for heating load prediction\n",
    "feature_importance_heating = best_rf_heating.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Get feature importances for cooling load prediction\n",
    "feature_importance_cooling = best_rf_cooling.named_steps['regressor'].feature_importances_\n",
    "\n",
    "# Combine feature importances with feature names\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance for Heating Load': feature_importance_heating,\n",
    "    'Importance for Cooling Load': feature_importance_cooling\n",
    "})\n",
    "\n",
    "# Sort features by importance for each target\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance for Heating Load', ascending=False)\n",
    "print(\"Feature importance for Heating Load:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance for Cooling Load', ascending=False)\n",
    "print(\"\\nFeature importance for Cooling Load:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WtDRWaX0xz4"
   },
   "source": [
    "## 3. First result Gaussian Process (10%)\n",
    "\n",
    "You will train two independent GPs, one to estimate HL and one to estimate CL. Each of the two GPs will be endowed with a composite kernel function $\\kappa_T = \\kappa_c \\cdot \\kappa_r + \\kappa_w$, where:\n",
    "- $\\kappa_c$ is a constant kernel\n",
    "- $\\kappa_r$ is an RBF kernel\n",
    "- $\\kappa_w$ is a White Noise kernel\n",
    "\n",
    "Evaluate those GPs with the corresponding test sets.\n",
    "\n",
    "**How do these results compare with those obtained using Random Forests?**\n",
    "\n",
    "**Discuss the contribution of the White Noise kernel and of the constant kernel to the final results**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DrepYjA80xz4"
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gaussian Process with Features selected by Random Forest (10%)\n",
    "\n",
    "Train now two independent GPs, using the same composite kernel as above, but now with those features indicated by RF as most relevant.\n",
    "\n",
    "**Is there any significant improvement over RF or GP with all the features?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gaussian Processes with ARD kernels (30%)\n",
    "\n",
    "Now use and ARD RBF kernel in the composite, that means enable a different lenghtscale for each feature. \n",
    "\n",
    "**Discuss the impact of the ARD kernel in the results of the GPs fit for each target.**\n",
    "\n",
    "**Print the parameters of the kernels after the GPs are fit. In particular discuss how the lengthscale achieved per each feature can be used as a proxy to estimate the relevance of each feature. Are these relevances aligned with those found by Random Forests?**\n",
    "\n",
    "**Discuss the impact of scaling or not the data in the conclusions extracted from the ARD results.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictive distributions (15%)\n",
    "\n",
    "The predictive distribution can be employed to asses the confidence on the predictions made by the GPs. For the GPs fit in parts 3 (composite kernel, single RBF lengthscale for all features) and 5 (ARD kernel) compute the predictions for the test data including mean and standard deviation.\n",
    "\n",
    "**For each GP produce an scatter plot of the absolute error of the predictions (true target minus mean of the predictive distributions) vs. the standard deviation of the corresponding predictive distribution. Is the standard deviation of the predictive distribution informative about the confidence in the predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced kernels (25%)\n",
    "\n",
    "Finally we will try to improve the results by using a more complicated kernel, which combine various covariance functions. Try to evaluate at least 10 different composite kernels by combining different instances of the basic kernels presented in class. Consider doing this programatically.\n",
    "\n",
    "**Discuss about how the diversity of the results in each target as you vary the composite kernels configuration.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework_Gaussian Process.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
